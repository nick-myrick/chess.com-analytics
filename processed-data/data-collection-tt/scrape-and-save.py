from bs4 import BeautifulSoup
import requests
import urllib.request
from urllib.request import urlopen
import json
import re
from datetime import datetime
import os

'''
Info:
Chess.com scraper generated by ChatGPT o1-mini.
Based off of https://github.com/golkir/titled-tuesday-chess-statistical-analysis/blob/main/scrape_and_save.py but removes Mongo tie in favor of a local file (I couldn't get MongoDB figured out and it seemed slower)

Function:
Goes through every Titled Tuesday game in reverse order starting at 2024.

Output:
Creates a "players" folder which contains every player found in the Titled Tuesday games, and
stores their match information.

Example player file:
{
    "username": "tptagain",
    "games": [
        {
            "white": false,
            "score": 1.0,
            "accuracy": 96.2,
            "rating": 3016,
            "tournament": "early-titled-tuesday-blitz-december-03-2024-5248885",
            "round": 1,
            "points": 1.0,
            "rank": 1,
            "possible_rank": 1
        },
        ...
    ]
}
'''

def ensure_directory(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)

def insert_if_not_exist(directory, username, player_doc):
    filepath = os.path.join(directory, f"{username}.json")
    if not os.path.exists(filepath):
        with open(filepath, 'w') as f:
            json.dump(player_doc, f, indent=4)

def push_array(directory, username, array_field, item):
    filepath = os.path.join(directory, f"{username}.json")
    if os.path.exists(filepath):
        with open(filepath, 'r') as f:
            data = json.load(f)
    else:
        data = {}
    if array_field not in data:
        data[array_field] = []
    data[array_field].append(item)
    with open(filepath, 'w') as f:
        json.dump(data, f, indent=4)

def get_element_at_index(directory, username, array_field, index):
    filepath = os.path.join(directory, f"{username}.json")
    if os.path.exists(filepath):
        with open(filepath, 'r') as f:
            data = json.load(f)
        if array_field in data and len(data[array_field]) > index:
            return data[array_field][index]
    return None

# Function to find an object with a specific property value
def find_object_by_property(array, property_name, target_value):
    for obj in array:
        if property_name in obj and obj[property_name] == target_value:
            return obj
    return None

# Function to get ranking
def get_ranking(original_dict, possible_next=None):
    # Sort the dictionary items based on the points in descending order
    sorted_users = sorted(original_dict.items(),
                          key=lambda x: x[1], reverse=True)

    # if we want to know the rank if the user wins next round
    if possible_next:
        sorted_users_possible = [(user, points + 1.0) for user, points in sorted_users]
    else:
        sorted_users_possible = sorted_users

    # Assign ranks to users with tied ranking
    ranked_dict = {}
    current_rank = 1
    previous_points = None
    for i, (user, points) in enumerate(sorted_users_possible):
        if i > 0 and points < previous_points:
            current_rank += 1
        ranked_dict[user] = current_rank
        previous_points = points

    return ranked_dict

# Function to get blank game data
def get_blank_game_data(user):
    game_data = {"white": False, "score": 0,
                 "accuracy": None, "rating": 0}
    return game_data

# Function to convert month string to numeric
def convert_month_to_numeric(month_str):
    month_numeric = datetime.strptime(month_str, "%B").month
    formatted_month = datetime(2000, month_numeric, 1).strftime("%m")
    return formatted_month

# Function to get game data
def get_game_data(game, username):
    # Define the regular expression for the entire block
    block_pattern = re.compile(
        r'\[White "(.*?)"\]\n\[Black "(.*?)"\]\n\[Result "(.*?)"\]')
    # Find matches in the larger data
    block_match = block_pattern.search(game["pgn"])
    # Create dictionaries to store results for each player
    game_data = {}
    # Extract player names and result if a match is found
    if block_match:
        white_player = block_match.group(1).lower()
        black_player = block_match.group(2).lower()
        result = block_match.group(3)
        # Extract scores from the result string
        scores = result.split('-')
        if scores[0] == "1/2" or scores[1] == "1/2":
            white_score = 0.5
            black_score = 0.5
        else:
            white_score = float(scores[0])
            black_score = float(scores[1])
        # Store scores in dictionaries
        score_to_record = white_score if white_player == username else black_score
        accuracy_to_record = None
        if "accuracies" in game:
            accuracy_to_record = game["accuracies"]["white"] if white_player == username else game["accuracies"]["black"]
        else:
            accuracy_to_record = None
        isWhite = True if username == white_player else False
        rating = game["white"]["rating"] if isWhite else game["black"]["rating"]

        game_data = {"white": isWhite, "score": score_to_record,
                     "accuracy": accuracy_to_record, "rating": rating}

    else:
        print("Pattern not found in the larger data.")
    return game_data

# Sample web page URLs and settings
tournaments_web_page = 'https://www.chess.com/tournament/live/titled-tuesdays?&page='
api_endpoint = "https://api.chess.com/pub/tournament/"
game_archives_endpoint = "https://api.chess.com/pub/player/{username}/games/{YYYY}/{MM}"
n_pages = 5

header = {
    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) '
                  'AppleWebKit/537.11 (KHTML, like Gecko) '
                  'Chrome/23.0.1271.64 Safari/537.11',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
    'Accept-Encoding': 'none',
    'Accept-Language': 'en-US,en;q=0.8',
    'Connection': 'keep-alive',
}

tournaments_class = "tournaments-live-name"

# Initialize local storage directory
players_directory = "players"
ensure_directory(players_directory)

tournaments = []
for p in range(1, n_pages + 1):
    # Call get method to request that page
    page = requests.get(tournaments_web_page + str(p), headers=header)
    # With the help of BeautifulSoup and html parser create soup
    soup = BeautifulSoup(page.content, "html.parser")
    tournament_pages = soup.find_all('a', {"class": tournaments_class})
    tournaments.extend(tournament_pages)

for tt, t in enumerate(tournaments):
    # total games and total available accuracy information for each game
    href = t["href"]
    # Take the first page of players (25 top players in the tournament)
    results_href = href + "?&players=1"
    index = href.rfind("/")
    tournament_name = href[index+1:]
    # Tournament api_endpoint to access
    url = api_endpoint + href[index+1:]

    # Parse month and year from the tournament URL
    match = re.search(r'-(\w+)-(\d+)-(\d+)-', href)
    if match:
        month_str = match.group(1)
        day = int(match.group(2))
        year = int(match.group(3))
        month_numeric = convert_month_to_numeric(month_str)
        print(f"Processing Tournament: {tournament_name}")
        print("Month (numeric):", month_numeric)
        print("Day:", day)
        print("Year:", year)
    else:
        print(f"Could not parse date from href: {href}")
        continue  # Skip this tournament if date parsing fails

    # Fetch tournament general information
    res = requests.get(url, headers=header, allow_redirects=True)
    if res.status_code != 200:
        print(f"Failed to fetch tournament data from {url}")
        continue
    tournament_general = res.json()

    # Initialize player files
    for player in tournament_general.get("players", []):
        username = player.get("username", "").lower()
        if not username:
            continue
        player_doc = {"username": username, "games": []}
        insert_if_not_exist(players_directory, username, player_doc)

    players_dict = {player_d['username'].lower(): 0.0
                   for player_d in tournament_general.get("players", [])}
    games_dict = {player_d['username'].lower(): {}
                  for player_d in tournament_general.get("players", [])}

    # Get all tournament games (1-25 place)
    page = requests.get(results_href, headers=header)
    # With the help of BeautifulSoup and html parser create soup
    results_page = BeautifulSoup(page.content, "html.parser")

    user_rows = results_page.find_all(
        'tr', {"class": "tournaments-live-view-results-row"})
    # Delete header row if present
    if user_rows and 'header' in user_rows[0].get('class', []):
        user_rows = user_rows[1:]

    # For each round
    total_rounds = 11

    for r in range(total_rounds):
        for u_index, user_row in enumerate(user_rows):
            # Extract the username from the user_row
            user_link = user_row.find('a', {"class": "user-username-component"})
            if not user_link:
                print(f"No username link found in user_row index {u_index}")
                continue  # Skip if username link is not found
            
            user_ = user_link.text.strip().lower()
            
            # Find the corresponding player in tournament_general["players"]
            player_info = find_object_by_property(tournament_general.get("players", []), "username", user_)
            if not player_info:
                print(f"Username '{user_}' not found in tournament_general['players']")
                continue  # Skip if player not found
            
            # Proceed with processing
            archives_endpoint_player = game_archives_endpoint.format(
                username=user_, YYYY=year, MM=month_numeric)
            round_result_class = "tournaments-live-view-player-result"
            rounds = user_row.find_all("a", {"class": round_result_class})
            
            # Select the round
            if r >= len(rounds):
                round_game_link = None
            else:
                round_game = rounds[r]
                round_game_link = round_game.get("href", None)
            
            # Get the game from archive endpoint
            monthly_games = requests.get(
                archives_endpoint_player, headers=header)
            if monthly_games.status_code != 200:
                monthly_json = {}
            else:
                monthly_json = monthly_games.json()
            
            if round_game_link is None or "games" not in monthly_json:
                game_data = get_blank_game_data(user_)
            else:
                game = find_object_by_property(
                    monthly_json["games"], "url", round_game_link)
                if game:
                    game_data = get_game_data(game, user_)
                else:
                    game_data = get_blank_game_data(user_)
            
            game_data["tournament"] = tournament_name
            game_data["round"] = r + 1
            
            # If it's the first round, just add points to 0, otherwise add points to previous points
            if r == 0:
                game_data["points"] = game_data["score"]
            else:
                # Retrieve previous game data
                previous_game = get_element_at_index(
                    players_directory, user_, "games", r - 1)
                if previous_game and "points" in previous_game:
                    game_data["points"] = previous_game["points"] + game_data["score"]
                else:
                    game_data["points"] = game_data["score"]
            
            players_dict[user_] = game_data["points"]
            games_dict[user_] = game_data
            
            # Calculate ranking when we reach the last user
            if u_index == len(user_rows) - 1:
                ranked_list = get_ranking(players_dict)
                # If penultimate rank, ask for hypothetical ranking
                ranked_list_possible = get_ranking(
                    players_dict, possible_next=True)
                for player in tournament_general.get("players", []):
                    player_username = player["username"].lower()
                    if player_username not in ranked_list:
                        continue
                    games_dict[player_username]["rank"] = ranked_list.get(player_username, None)
                    games_dict[player_username]["possible_rank"] = ranked_list_possible.get(player_username, None)
                    push_array(players_directory, player_username, "games",
                              games_dict[player_username])
    